{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmr1532/kaggle-projects/blob/master/mnistpred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Nq4SjBhPqxAc",
        "colab_type": "code",
        "outputId": "aa0365bf-ce91-49f9-9d63-bb1b24474bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "if not os.path.exists(os.path.dirname(filename)):\n",
        "  os.makedirs(os.path.dirname(filename))\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y_FbGGKi1ERD",
        "colab_type": "code",
        "outputId": "743fcdfa-087b-4e78-99df-86f378f39e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrVVa4kH1v69",
        "colab_type": "code",
        "outputId": "0d28be4d-3b4d-4a6b-c347-1209353d09fb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv to /content\n",
            " 83% 61.0M/73.2M [00:00<00:00, 57.3MB/s]\n",
            "100% 73.2M/73.2M [00:00<00:00, 94.0MB/s]\n",
            "Downloading test.csv to /content\n",
            " 90% 44.0M/48.8M [00:00<00:00, 69.5MB/s]\n",
            "100% 48.8M/48.8M [00:00<00:00, 140MB/s] \n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/235k [00:00<?, ?B/s]\n",
            "100% 235k/235k [00:00<00:00, 72.4MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c63d9b3c-a26f-4305-b2bc-1053ddb8dda4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c63d9b3c-a26f-4305-b2bc-1053ddb8dda4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b0445ycK1-u_",
        "colab_type": "code",
        "outputId": "4082ce95-8826-43f0-d2fa-cdb60477c8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404 - Not Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UqlsH1m-2FF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQB55xI927fI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy\n",
        "train1=pandas.read_csv(\"train.csv\")\n",
        "test1=pandas.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oPVjVnoB3x8k",
        "colab_type": "code",
        "outputId": "78f64034-6e56-460f-cb3a-e1351777e759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "print(train1.shape)\n",
        "print(train1.info())\n",
        "train1.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42000 entries, 0 to 41999\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: int64(785)\n",
            "memory usage: 251.5 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "9hZOAaJZ39dp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGaB-PUo4PT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = numpy.asarray(train1.drop('label',axis=1),dtype=numpy.float32).reshape(-1,28,28)\n",
        "yhat = numpy.asarray(train1['label'])\n",
        "\n",
        "# Generate random indices for creating a random validation set with 20% of the labelled data\n",
        "validx = (numpy.random.uniform(size=len(X)) <= 0.2)\n",
        "\n",
        "# Create training set (80% of the labelled data)\n",
        "X_trn = X[~validx]\n",
        "y_trn = yhat[~validx]\n",
        "\n",
        "# Create validation set (20% of the labelled data)\n",
        "X_val = X[validx]\n",
        "y_val = yhat[validx]\n",
        "\n",
        "# Create the test set\n",
        "X_tes = numpy.asarray(test1,dtype=numpy.float32).reshape(-1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j7G0heog74sS",
        "colab_type": "code",
        "outputId": "b5733bd8-1ae3-4b81-f586-d3bf5b679dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "nvis = 12\n",
        "plt.imshow(numpy.concatenate(X_trn[:nvis],axis=1),cmap='gray',vmin=0,vmax=255)\n",
        "plt.show()\n",
        "\n",
        "# Print the corresponding labels to check they match\n",
        "y_trn[:nvis]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA+CAYAAAA71+DtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 7, 3, 8, 1, 1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ejQ7CsOgKg7v",
        "colab_type": "code",
        "outputId": "80ab8abf-143c-4e4b-cdd3-6c6f4fea26b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10764
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "import keras,numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "model=Sequential()\n",
        "model.add(Flatten()) #Since the dataloader outputs 28x28 images, flatten it to 784\n",
        "model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "y=model.fit(X_trn,keras.utils.to_categorical(y_trn, num_classes=10, dtype='int'), epochs=300, batch_size=128)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/300\n",
            "33585/33585 [==============================] - 2s 59us/step - loss: 8.0218 - acc: 0.4960\n",
            "Epoch 2/300\n",
            "33585/33585 [==============================] - 1s 39us/step - loss: 5.0284 - acc: 0.6821\n",
            "Epoch 3/300\n",
            "33585/33585 [==============================] - 1s 38us/step - loss: 4.6260 - acc: 0.7082\n",
            "Epoch 4/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 4.4403 - acc: 0.7207\n",
            "Epoch 5/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 4.3109 - acc: 0.7289\n",
            "Epoch 6/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 3.6397 - acc: 0.7702\n",
            "Epoch 7/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 2.4884 - acc: 0.8413\n",
            "Epoch 8/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 2.4022 - acc: 0.8471\n",
            "Epoch 9/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.3036 - acc: 0.8534\n",
            "Epoch 10/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 2.2660 - acc: 0.8561\n",
            "Epoch 11/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.2062 - acc: 0.8597\n",
            "Epoch 12/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 2.1931 - acc: 0.8609\n",
            "Epoch 13/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 2.1757 - acc: 0.8622\n",
            "Epoch 14/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.1563 - acc: 0.8632\n",
            "Epoch 15/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.0889 - acc: 0.8683\n",
            "Epoch 16/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.1080 - acc: 0.8668\n",
            "Epoch 17/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.0473 - acc: 0.8706\n",
            "Epoch 18/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.0521 - acc: 0.8699\n",
            "Epoch 19/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.0446 - acc: 0.8709\n",
            "Epoch 20/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 2.0359 - acc: 0.8714\n",
            "Epoch 21/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 1.9987 - acc: 0.8735\n",
            "Epoch 22/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.9743 - acc: 0.8752\n",
            "Epoch 23/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.9791 - acc: 0.8751\n",
            "Epoch 24/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 1.9686 - acc: 0.8757\n",
            "Epoch 25/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 1.9465 - acc: 0.8772\n",
            "Epoch 26/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.9359 - acc: 0.8780\n",
            "Epoch 27/300\n",
            "33585/33585 [==============================] - 1s 38us/step - loss: 1.9589 - acc: 0.8766\n",
            "Epoch 28/300\n",
            "33585/33585 [==============================] - 1s 40us/step - loss: 1.9104 - acc: 0.8797\n",
            "Epoch 29/300\n",
            "33585/33585 [==============================] - 1s 41us/step - loss: 1.9044 - acc: 0.8801\n",
            "Epoch 30/300\n",
            "33585/33585 [==============================] - 1s 40us/step - loss: 1.9028 - acc: 0.8806\n",
            "Epoch 31/300\n",
            "33585/33585 [==============================] - 1s 41us/step - loss: 1.8911 - acc: 0.8810\n",
            "Epoch 32/300\n",
            "33585/33585 [==============================] - 1s 39us/step - loss: 1.8851 - acc: 0.8816\n",
            "Epoch 33/300\n",
            "33585/33585 [==============================] - 1s 39us/step - loss: 1.8672 - acc: 0.8829\n",
            "Epoch 34/300\n",
            "33585/33585 [==============================] - 1s 40us/step - loss: 1.8645 - acc: 0.8827\n",
            "Epoch 35/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 1.8602 - acc: 0.8831\n",
            "Epoch 36/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.8501 - acc: 0.8840\n",
            "Epoch 37/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.8474 - acc: 0.8839\n",
            "Epoch 38/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.8433 - acc: 0.8842\n",
            "Epoch 39/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 1.8292 - acc: 0.8855\n",
            "Epoch 40/300\n",
            "33585/33585 [==============================] - 1s 39us/step - loss: 1.8232 - acc: 0.8853\n",
            "Epoch 41/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.9094 - acc: 0.9401\n",
            "Epoch 42/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.5675 - acc: 0.9617\n",
            "Epoch 43/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.5223 - acc: 0.9648\n",
            "Epoch 44/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.4730 - acc: 0.9685\n",
            "Epoch 45/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.4550 - acc: 0.9693\n",
            "Epoch 46/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.4581 - acc: 0.9690\n",
            "Epoch 47/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.4292 - acc: 0.9707\n",
            "Epoch 48/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3998 - acc: 0.9730\n",
            "Epoch 49/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.3781 - acc: 0.9741\n",
            "Epoch 50/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.3980 - acc: 0.9731\n",
            "Epoch 51/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.3680 - acc: 0.9756\n",
            "Epoch 52/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3528 - acc: 0.9765\n",
            "Epoch 53/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3424 - acc: 0.9768\n",
            "Epoch 54/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3267 - acc: 0.9777\n",
            "Epoch 55/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3377 - acc: 0.9772\n",
            "Epoch 56/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3154 - acc: 0.9787\n",
            "Epoch 57/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2977 - acc: 0.9798\n",
            "Epoch 58/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.3040 - acc: 0.9794\n",
            "Epoch 59/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2837 - acc: 0.9807\n",
            "Epoch 60/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.3072 - acc: 0.9793\n",
            "Epoch 61/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2859 - acc: 0.9807\n",
            "Epoch 62/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2739 - acc: 0.9816\n",
            "Epoch 63/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2601 - acc: 0.9825\n",
            "Epoch 64/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2669 - acc: 0.9823\n",
            "Epoch 65/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2584 - acc: 0.9826\n",
            "Epoch 66/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2523 - acc: 0.9828\n",
            "Epoch 67/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.2374 - acc: 0.9841\n",
            "Epoch 68/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2471 - acc: 0.9831\n",
            "Epoch 69/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2262 - acc: 0.9846\n",
            "Epoch 70/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2267 - acc: 0.9847\n",
            "Epoch 71/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2284 - acc: 0.9845\n",
            "Epoch 72/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2273 - acc: 0.9848\n",
            "Epoch 73/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2154 - acc: 0.9855\n",
            "Epoch 74/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2149 - acc: 0.9855\n",
            "Epoch 75/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2139 - acc: 0.9855\n",
            "Epoch 76/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.2193 - acc: 0.9852\n",
            "Epoch 77/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2212 - acc: 0.9851\n",
            "Epoch 78/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2042 - acc: 0.9864\n",
            "Epoch 79/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.2190 - acc: 0.9852\n",
            "Epoch 80/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.2030 - acc: 0.9864\n",
            "Epoch 81/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1984 - acc: 0.9867\n",
            "Epoch 82/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1928 - acc: 0.9872\n",
            "Epoch 83/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.2013 - acc: 0.9866\n",
            "Epoch 84/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1969 - acc: 0.9869\n",
            "Epoch 85/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.2028 - acc: 0.9864\n",
            "Epoch 86/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1894 - acc: 0.9871\n",
            "Epoch 87/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1910 - acc: 0.9872\n",
            "Epoch 88/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1845 - acc: 0.9875\n",
            "Epoch 89/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1871 - acc: 0.9876\n",
            "Epoch 90/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1753 - acc: 0.9886\n",
            "Epoch 91/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1805 - acc: 0.9880\n",
            "Epoch 92/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1783 - acc: 0.9882\n",
            "Epoch 93/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1785 - acc: 0.9882\n",
            "Epoch 94/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1779 - acc: 0.9882\n",
            "Epoch 95/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1719 - acc: 0.9887\n",
            "Epoch 96/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1656 - acc: 0.9891\n",
            "Epoch 97/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1650 - acc: 0.9892\n",
            "Epoch 98/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1664 - acc: 0.9892\n",
            "Epoch 99/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1636 - acc: 0.9893\n",
            "Epoch 100/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1602 - acc: 0.9895\n",
            "Epoch 101/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1633 - acc: 0.9892\n",
            "Epoch 102/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1569 - acc: 0.9898\n",
            "Epoch 103/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1602 - acc: 0.9896\n",
            "Epoch 104/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1537 - acc: 0.9900\n",
            "Epoch 105/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1543 - acc: 0.9898\n",
            "Epoch 106/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1559 - acc: 0.9899\n",
            "Epoch 107/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1537 - acc: 0.9901\n",
            "Epoch 108/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1548 - acc: 0.9899\n",
            "Epoch 109/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1620 - acc: 0.9893\n",
            "Epoch 110/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1551 - acc: 0.9898\n",
            "Epoch 111/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1598 - acc: 0.9895\n",
            "Epoch 112/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1615 - acc: 0.9893\n",
            "Epoch 113/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1571 - acc: 0.9895\n",
            "Epoch 114/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1548 - acc: 0.9898\n",
            "Epoch 115/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1484 - acc: 0.9904\n",
            "Epoch 116/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1478 - acc: 0.9905\n",
            "Epoch 117/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1443 - acc: 0.9908\n",
            "Epoch 118/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1502 - acc: 0.9902\n",
            "Epoch 119/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1498 - acc: 0.9902\n",
            "Epoch 120/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1413 - acc: 0.9908\n",
            "Epoch 121/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1534 - acc: 0.9900\n",
            "Epoch 122/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1494 - acc: 0.9901\n",
            "Epoch 123/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1475 - acc: 0.9905\n",
            "Epoch 124/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1471 - acc: 0.9904\n",
            "Epoch 125/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1452 - acc: 0.9907\n",
            "Epoch 126/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1494 - acc: 0.9902\n",
            "Epoch 127/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1481 - acc: 0.9905\n",
            "Epoch 128/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1410 - acc: 0.9908\n",
            "Epoch 129/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1435 - acc: 0.9906\n",
            "Epoch 130/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1466 - acc: 0.9904\n",
            "Epoch 131/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1428 - acc: 0.9908\n",
            "Epoch 132/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1417 - acc: 0.9907\n",
            "Epoch 133/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1420 - acc: 0.9907\n",
            "Epoch 134/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1358 - acc: 0.9912\n",
            "Epoch 135/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1404 - acc: 0.9907\n",
            "Epoch 136/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1389 - acc: 0.9909\n",
            "Epoch 137/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1476 - acc: 0.9902\n",
            "Epoch 138/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1362 - acc: 0.9911\n",
            "Epoch 139/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1375 - acc: 0.9910\n",
            "Epoch 140/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1419 - acc: 0.9906\n",
            "Epoch 141/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1385 - acc: 0.9909\n",
            "Epoch 142/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1368 - acc: 0.9909\n",
            "Epoch 143/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1352 - acc: 0.9913\n",
            "Epoch 144/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1344 - acc: 0.9913\n",
            "Epoch 145/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1323 - acc: 0.9915\n",
            "Epoch 146/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1331 - acc: 0.9913\n",
            "Epoch 147/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1287 - acc: 0.9918\n",
            "Epoch 148/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1308 - acc: 0.9916\n",
            "Epoch 149/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1306 - acc: 0.9915\n",
            "Epoch 150/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1257 - acc: 0.9921\n",
            "Epoch 151/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1291 - acc: 0.9917\n",
            "Epoch 152/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1264 - acc: 0.9920\n",
            "Epoch 153/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1293 - acc: 0.9918\n",
            "Epoch 154/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1297 - acc: 0.9917\n",
            "Epoch 155/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1265 - acc: 0.9921\n",
            "Epoch 156/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1239 - acc: 0.9922\n",
            "Epoch 157/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1247 - acc: 0.9921\n",
            "Epoch 158/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1283 - acc: 0.9918\n",
            "Epoch 159/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1255 - acc: 0.9921\n",
            "Epoch 160/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1255 - acc: 0.9920\n",
            "Epoch 161/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1245 - acc: 0.9922\n",
            "Epoch 162/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1262 - acc: 0.9920\n",
            "Epoch 163/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1284 - acc: 0.9918\n",
            "Epoch 164/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1244 - acc: 0.9920\n",
            "Epoch 165/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1244 - acc: 0.9920\n",
            "Epoch 166/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1317 - acc: 0.9915\n",
            "Epoch 167/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1256 - acc: 0.9920\n",
            "Epoch 168/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1244 - acc: 0.9920\n",
            "Epoch 169/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1261 - acc: 0.9918\n",
            "Epoch 170/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1232 - acc: 0.9922\n",
            "Epoch 171/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1250 - acc: 0.9921\n",
            "Epoch 172/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1262 - acc: 0.9919\n",
            "Epoch 173/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1243 - acc: 0.9920\n",
            "Epoch 174/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1245 - acc: 0.9921\n",
            "Epoch 175/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1212 - acc: 0.9924\n",
            "Epoch 176/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1210 - acc: 0.9923\n",
            "Epoch 177/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1193 - acc: 0.9925\n",
            "Epoch 178/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1226 - acc: 0.9921\n",
            "Epoch 179/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1302 - acc: 0.9916\n",
            "Epoch 180/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1254 - acc: 0.9919\n",
            "Epoch 181/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1213 - acc: 0.9923\n",
            "Epoch 182/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1197 - acc: 0.9924\n",
            "Epoch 183/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1229 - acc: 0.9922\n",
            "Epoch 184/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1228 - acc: 0.9922\n",
            "Epoch 185/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1223 - acc: 0.9922\n",
            "Epoch 186/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1235 - acc: 0.9921\n",
            "Epoch 187/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1220 - acc: 0.9922\n",
            "Epoch 188/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1205 - acc: 0.9924\n",
            "Epoch 189/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1246 - acc: 0.9918\n",
            "Epoch 190/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1220 - acc: 0.9923\n",
            "Epoch 191/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1207 - acc: 0.9923\n",
            "Epoch 192/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1207 - acc: 0.9922\n",
            "Epoch 193/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1190 - acc: 0.9926\n",
            "Epoch 194/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1181 - acc: 0.9926\n",
            "Epoch 195/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1178 - acc: 0.9925\n",
            "Epoch 196/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1186 - acc: 0.9925\n",
            "Epoch 197/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1207 - acc: 0.9922\n",
            "Epoch 198/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1178 - acc: 0.9926\n",
            "Epoch 199/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1194 - acc: 0.9924\n",
            "Epoch 200/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1186 - acc: 0.9924\n",
            "Epoch 201/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1165 - acc: 0.9926\n",
            "Epoch 202/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1201 - acc: 0.9923\n",
            "Epoch 203/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1249 - acc: 0.9919\n",
            "Epoch 204/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1178 - acc: 0.9925\n",
            "Epoch 205/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1204 - acc: 0.9922\n",
            "Epoch 206/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1212 - acc: 0.9923\n",
            "Epoch 207/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1176 - acc: 0.9922\n",
            "Epoch 208/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1163 - acc: 0.9925\n",
            "Epoch 209/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1186 - acc: 0.9925\n",
            "Epoch 210/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1148 - acc: 0.9927\n",
            "Epoch 211/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1179 - acc: 0.9926\n",
            "Epoch 212/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1175 - acc: 0.9926\n",
            "Epoch 213/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1160 - acc: 0.9927\n",
            "Epoch 214/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1148 - acc: 0.9928\n",
            "Epoch 215/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1161 - acc: 0.9926\n",
            "Epoch 216/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1153 - acc: 0.9927\n",
            "Epoch 217/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1128 - acc: 0.9929\n",
            "Epoch 218/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1132 - acc: 0.9929\n",
            "Epoch 219/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1143 - acc: 0.9929\n",
            "Epoch 220/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1144 - acc: 0.9928\n",
            "Epoch 221/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1154 - acc: 0.9927\n",
            "Epoch 222/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1154 - acc: 0.9927\n",
            "Epoch 223/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1161 - acc: 0.9927\n",
            "Epoch 224/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1141 - acc: 0.9928\n",
            "Epoch 225/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1159 - acc: 0.9926\n",
            "Epoch 226/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1128 - acc: 0.9929\n",
            "Epoch 227/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1134 - acc: 0.9929\n",
            "Epoch 228/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1160 - acc: 0.9927\n",
            "Epoch 229/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1134 - acc: 0.9929\n",
            "Epoch 230/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1116 - acc: 0.9930\n",
            "Epoch 231/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1134 - acc: 0.9929\n",
            "Epoch 232/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1128 - acc: 0.9929\n",
            "Epoch 233/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1128 - acc: 0.9930\n",
            "Epoch 234/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1124 - acc: 0.9930\n",
            "Epoch 235/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1131 - acc: 0.9929\n",
            "Epoch 236/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1138 - acc: 0.9928\n",
            "Epoch 237/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9930\n",
            "Epoch 238/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 239/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 240/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 241/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 242/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 243/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 244/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 245/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 246/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 247/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 248/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 249/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 250/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 251/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 252/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 253/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 254/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 255/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 256/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 257/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 258/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 259/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 260/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 261/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 262/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 263/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 264/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 265/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 266/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 267/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 268/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 269/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 270/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 271/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 272/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 273/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 274/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 275/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 276/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 277/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 278/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 279/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 280/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 281/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 282/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 283/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 284/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 285/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 286/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 287/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 288/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 289/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 290/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 291/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 292/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 293/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 294/300\n",
            "33585/33585 [==============================] - 1s 37us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 295/300\n",
            "33585/33585 [==============================] - 1s 36us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 296/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 297/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 298/300\n",
            "33585/33585 [==============================] - 1s 35us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 299/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n",
            "Epoch 300/300\n",
            "33585/33585 [==============================] - 1s 34us/step - loss: 0.1118 - acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-88462f3f2e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object does not support indexing"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zdnrPnyXwW9Y",
        "colab_type": "code",
        "outputId": "36e94535-ce84-4ebd-cf53-635922e80544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = model.predict(X_tes)\n",
        "output = np.argmax(predictions,axis=1)\n",
        "print(output)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 9 ... 3 9 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0s_7VJ0rwnc3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub = pandas.DataFrame({\"ImageId\":numpy.arange(1,28001),\"Label\":output})\n",
        "sub.to_csv(\"sub.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Sm4yA0E2CLe",
        "colab_type": "code",
        "outputId": "22da2a60-af1f-490e-bfab-cc82603435ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c digit-recognizer -f sub.csv -m \"submission2\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 208k/208k [00:03<00:00, 63.1kB/s]\n",
            "Successfully submitted to Digit Recognizer"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SqpZE4wJ2Gr-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}